{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jA2hPk6iArOmYbXivEcxZWD6MwHOAbZE",
      "authorship_tag": "ABX9TyN+moZFVplMemCt4rlNlz9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tn-220/EmergingClass/blob/main/cats_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a data set from Microsoft at Kaggle which includes cat and dog images. You can download the dataset from:\n",
        "\n",
        "https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765"
      ],
      "metadata": {
        "id": "g0z7InCVSkEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the data set, unzip it.\n",
        "\n"
      ],
      "metadata": {
        "id": "vuKHXPUmTCwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have put around 1500 cat images at MyDrive/pets/Cats\n",
        "\n",
        "Also I have put around 1500 dog images at MyDrive/pets/Dogs"
      ],
      "metadata": {
        "id": "iaL6VnhMTUT7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpCcVjf3zbdY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                # a library used for working with arrays and numerical operations.\n",
        "import matplotlib.pyplot as plt   # a data visualization library\n",
        "import os                         # a module that provides a way of interacting with the operating system\n",
        "import cv2                        # a library for image and video processing.\n",
        "from tqdm import tqdm             # a library that provides a progress bar for iterative operations in a loop or on an iterable object.\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/pets/\"   # This is my directory which includes two subdirectories of Cats and Dogs. You may place yours\n",
        "\n",
        "categories = [\"Dogs\",\"Cats\"]\n",
        "\n",
        "for item in categories: \n",
        "    i = 1\n",
        "    path = os.path.join(data_dir,item)  # create path to dogs and cats\n",
        "    for img in os.listdir(path):  # iterate over each image\n",
        "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "        plt.imshow(img_array, cmap='gray')  # graph it\n",
        "        plt.show()  # display!\n",
        "        print(img)\n",
        "        i = i+1\n",
        "        if(i>3):\n",
        "          break  # This is to see few of these images\n"
      ],
      "metadata": {
        "id": "WNyzmS04sJuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_array)"
      ],
      "metadata": {
        "id": "VroVZUUAsoyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_array.shape)"
      ],
      "metadata": {
        "id": "xoUwDiGcss4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 100\n",
        "\n",
        "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "plt.imshow(new_array, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ELnqBHajsyvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 200\n",
        "\n",
        "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "plt.imshow(new_array, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rB_lDOpbs4m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for item in categories: \n",
        "\n",
        "        path = os.path.join(data_dir,item)  \n",
        "        class_num = categories.index(item)  # get the classification  (0 or a 1). 0 is dog and cat is 1\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                training_data.append([new_array, class_num])  # add the image to the training data\n",
        "            except Exception as e:  # to handle any exceptions. If an exception occurs, the code ignores it and continues to the next iteration.\n",
        "                pass"
      ],
      "metadata": {
        "id": "3vfyaKsGtNHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_training_data()\n",
        "\n",
        "print(\"\\n\",len(training_data))\n",
        "print(\"\\n\",type(training_data))"
      ],
      "metadata": {
        "id": "wJN_ptArZq0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(training_data))\n",
        "print(training_data[0])"
      ],
      "metadata": {
        "id": "vKDYga6f7rPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "\"\"\"\n",
        "The code above shuffles the order of elements in the list training_data randomly. \n",
        "In this case, it is likely being used to ensure that the model doesn't accidentally learn \n",
        "to classify images based on their order in the dataset\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "IJMjJVBMteSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in training_data[:10]:\n",
        "    print(sample[1])\n"
      ],
      "metadata": {
        "id": "o5uuuFWHtiOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(training_data)"
      ],
      "metadata": {
        "id": "olvGLXARaQ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)    # (batch_size, height, width, channels), 1 channel for grayscale \n"
      ],
      "metadata": {
        "id": "3jQ07-JVtnH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle       #  a module used for serializing and de-serializing Python objects.\n",
        "\n",
        "\"\"\" By using pickle, we can save time and resources that would otherwise \n",
        "be spent on preprocessing the data every time the script is run. \"\"\"\n",
        "\n",
        "pickle_out = open(\"X.pickle\",\"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\",\"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "metadata": {
        "id": "u0nVTLAHtt4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to loadi the data that was previously saved using the pickle.dump() function.\n",
        "\n",
        "pickle_in = open(\"X.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"y.pickle\",\"rb\")\n",
        "y = pickle.load(pickle_in)\n"
      ],
      "metadata": {
        "id": "Q5GjSMobtylo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "X = X/255.0\n",
        "\n",
        "model = Sequential()  #  create a new sequential model in Keras where you can easily add, remove or modify the layers in the model.\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:])) # the layer will learn 256 different filters during training, each looking for a different feature in the input image.\n",
        "model.add(Activation('relu'))             # an activation function that returns the input if it is positive, and 0 otherwise.\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # to reduce the size of the output feature maps while preserving the most important features.\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))  # adds a fully connected layer with 64 neurons to the neural network model.\n",
        "\n",
        "model.add(Dense(1))   # adds a fully connected layer with a single neuron to the neural network model.\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(np.array(X), np.array(y), batch_size=32, epochs=20, validation_split=0.3)\n",
        "\n"
      ],
      "metadata": {
        "id": "gC0ycIQf9r75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch_size:** refers to the number of training examples utilized in one iteration during the training process. During training, the data is divided into batches, and the model's parameters are updated based on the average of the gradients computed for each batch. Setting the batch size too small can lead to noisy gradients, and setting it too large can lead to memory issues.\n",
        "\n",
        "\n",
        "**Epochs:** refer to the number of times the training process goes through the entire dataset. Each epoch consists of one full iteration through the entire training dataset.\n",
        "\n",
        "\n",
        "**Validation_split:** is the fraction of the training dataset that is held out and used as a validation set during training. The model is trained on the training dataset, and its performance is evaluated on the validation set after each epoch. The validation set is used to monitor the model's performance on data it has not seen during training and can help detect overfitting."
      ],
      "metadata": {
        "id": "6ARvAgwjUz9X"
      }
    }
  ]
}